{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":236,"status":"ok","timestamp":1674470456285,"user":{"displayName":"Giulia Rizzi","userId":"13349830956359138572"},"user_tz":-60},"id":"eLfw9IFGFBIE"},"outputs":[],"source":["path = r'./Data/data_practicephase_cleardev/data_practicephase_cleardev/'"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"_zxlSB0dwHCB"},"source":["## BERT\n","\n","This code will fine-tune the BERT model on the training data, and then test the model on the test data, printing the accuracy of the predictions. In this example, the dataframe is expected to have two columns, one for the text (named \"text\") and one for the labels (named \"hard_label\"). The labels are expected to be in boolean format, 0 or 1.\n","You may need to import tokenizer from transformers library before using it."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Adopted parameters:\n","\n","BERT: BertForSequenceClassification, pretrained bert-base-uncased\n","\n","Epoch = 20\n","\n","Optimizer: Adam Linear wormup and decay lr=2e-5, eps=1e-8\n","\n","Tokenizer: bert-base-uncased\n"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":7768,"status":"ok","timestamp":1674470472076,"user":{"displayName":"Giulia Rizzi","userId":"13349830956359138572"},"user_tz":-60},"id":"jDkxeN1qwLYA"},"outputs":[],"source":["import pandas as pd\n","from transformers import BertForSequenceClassification, AdamW, BertConfig\n","from transformers import BertTokenizer\n","import torch\n","from tqdm import tqdm\n","import re"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Load Data"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":163,"status":"ok","timestamp":1674470979121,"user":{"displayName":"Giulia Rizzi","userId":"13349830956359138572"},"user_tz":-60},"id":"GcseVfNiOY-F"},"outputs":[],"source":["def create_text_user(data):\n","\n","    user_conversations = []\n","    \n","    for conversation in data:\n","        all_conversation = re.findall(r'\"(.*?)\"', conversation)\n","        user_conversation = all_conversation[3] + '. ' + all_conversation[7]\n","        user_conversations.append(user_conversation)\n","\n","    return user_conversations"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":178,"status":"ok","timestamp":1674470474360,"user":{"displayName":"Giulia Rizzi","userId":"13349830956359138572"},"user_tz":-60},"id":"9mq1ysz2FGCp"},"outputs":[],"source":["# datasets paths\n","convabuse_train = path + './ConvAbuse_dataset/ConvAbuse_train.json'\n","convabuse_dev = path + './ConvAbuse_dataset/ConvAbuse_dev.json'\n","\n","brexit_path_train = path + '/HS-Brexit_dataset/HS-Brexit_train.json'\n","brexit_path_dev = path + '/HS-Brexit_dataset/HS-Brexit_dev.json'\n","\n","MD_train = path + './MD-Agreement_dataset/MD-Agreement_train.json'\n","MD_dev = path + './MD-Agreement_dataset/MD-Agreement_dev.json'\n","\n","# Armis dataset is not consider because the selected pre-trained bert model doesn't recognize arabic\n","#armis_train = path + './ArMIS_dataset/ArMIS_train.json'\n","#armis_dev = path + './ArMIS_dataset/ArMIS_dev.json'\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":194,"status":"ok","timestamp":1674470558962,"user":{"displayName":"Giulia Rizzi","userId":"13349830956359138572"},"user_tz":-60},"id":"JP2tAOvpFU-9"},"outputs":[],"source":["# import and concat train datasets\n","df = pd.read_json(brexit_path_train, orient='index')\n","df = df[['text', 'hard_label']]\n","\n","df2 = pd.read_json(convabuse_train, orient='index')\n","df2 = df2[['text', 'hard_label']]\n","all = create_text_user(df2['text'])\n","df2['text']= all\n","\n","df3 = pd.read_json(MD_train, orient='index')\n","df3 = df3[['text', 'hard_label']]\n","\n","# concatenate df\n","df_tot = df.append(df2)\n","df_tot = df_tot.append(df3)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"708DuD3kRjeu"},"outputs":[],"source":["# import and concat dev datasets\n","df_t = pd.read_json(brexit_path_dev, orient='index')\n","df_t = df_t[['text', 'hard_label']]\n","\n","df2_t = pd.read_json(convabuse_dev, orient='index')\n","df2_t = df2_t[['text', 'hard_label']]\n","all = create_text_user(df2_t['text'])\n","df2_t['text']= all\n","\n","df3_t = pd.read_json(MD_dev, orient='index')\n","df3_t = df3_t[['text', 'hard_label']]\n","\n","#concat\n","df_dev = df_t.append(df2_t)\n","df_dev = df_dev.append(df3_t)"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"TQaKt_0ER9-o"},"outputs":[{"data":{"text/plain":["413"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["import gc\n","del df, df2, df3, \n","del df_t, df2_t, df3_t, all\n","del convabuse_train, convabuse_dev ,brexit_path_train, brexit_path_dev, MD_train, MD_dev \n","gc.collect()"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":232,"status":"ok","timestamp":1674471124527,"user":{"displayName":"Giulia Rizzi","userId":"13349830956359138572"},"user_tz":-60},"id":"ZQNE_Sy9y6hh","outputId":"b6e60147-db4e-47ca-f3b5-75c992487c79"},"outputs":[{"data":{"text/plain":["device(type='cuda')"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["# Define the device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","device"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["1.7.0+cu110\n"]}],"source":["print(torch. __version__)\n","#python -m pip install torch==1.7.0 -f https://download.pytorch.org/whl/torch_stable.html"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Define BERT Model"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1788,"status":"ok","timestamp":1674471129658,"user":{"displayName":"Giulia Rizzi","userId":"13349830956359138572"},"user_tz":-60},"id":"OS0wo7T9wiZ1","outputId":"3d7d84f1-7add-4bc0-f575-0b56cb1b3f35"},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading: 100%|██████████| 440M/440M [00:49<00:00, 8.91MB/s]\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["# Load the BERT model\n","model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2, output_attentions=False, output_hidden_states=False)"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1734,"status":"ok","timestamp":1674471134227,"user":{"displayName":"Giulia Rizzi","userId":"13349830956359138572"},"user_tz":-60},"id":"oCBKXn5uwk1l","outputId":"5773f77b-82bb-4602-db72-34f8abfca84a"},"outputs":[{"data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["# Move the model to the device\n","model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":183,"status":"ok","timestamp":1674471137644,"user":{"displayName":"Giulia Rizzi","userId":"13349830956359138572"},"user_tz":-60},"id":"aN6KI_dhwo3e","outputId":"a6916821-dadb-4ce6-aaa7-f8bd0d1d54f3"},"outputs":[],"source":["# Define the optimizer and schedule (linear warmup and decay)\n","optimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8)"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":456,"status":"ok","timestamp":1674471139217,"user":{"displayName":"Giulia Rizzi","userId":"13349830956359138572"},"user_tz":-60},"id":"6YabWrbMw6A_"},"outputs":[],"source":["tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":168,"status":"ok","timestamp":1674471141693,"user":{"displayName":"Giulia Rizzi","userId":"13349830956359138572"},"user_tz":-60},"id":"ekFGKmpnwqos"},"outputs":[],"source":["# Helper function for formatting inputs\n","def format_inputs(text, labels):\n","    input_ids = torch.tensor([tokenizer.encode(text, add_special_tokens=True)])\n","    attention_mask = torch.tensor([[1]*len(input_ids[0])])\n","    labels = torch.tensor([labels])\n","    return input_ids, attention_mask, labels"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Fine tune the model"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tJRfZVmlwsxy","outputId":"8c2e16dd-e7aa-4cb0-bde6-cae3e630e0f4"},"outputs":[{"name":"stderr","output_type":"stream","text":["  5%|▌         | 1/20 [11:02<3:29:43, 662.29s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 1, Loss: 0.4107941988528437\n"]},{"name":"stderr","output_type":"stream","text":[" 10%|█         | 2/20 [21:41<3:16:37, 655.41s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 2, Loss: 0.2960391748704165\n"]},{"name":"stderr","output_type":"stream","text":[" 15%|█▌        | 3/20 [32:24<3:04:36, 651.58s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 3, Loss: 0.22509947845786912\n"]},{"name":"stderr","output_type":"stream","text":[" 20%|██        | 4/20 [43:05<2:52:53, 648.34s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 4, Loss: 0.15464628059579233\n"]},{"name":"stderr","output_type":"stream","text":[" 25%|██▌       | 5/20 [53:46<2:41:35, 646.40s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 5, Loss: 0.1708090500488252\n"]},{"name":"stderr","output_type":"stream","text":[" 30%|███       | 6/20 [1:04:29<2:30:33, 645.24s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 6, Loss: 0.21436964553669702\n"]},{"name":"stderr","output_type":"stream","text":[" 35%|███▌      | 7/20 [1:15:12<2:19:38, 644.54s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 7, Loss: 0.3209068367269518\n"]},{"name":"stderr","output_type":"stream","text":[" 40%|████      | 8/20 [1:25:54<2:08:46, 643.91s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 8, Loss: 0.42712416746409687\n"]},{"name":"stderr","output_type":"stream","text":[" 45%|████▌     | 9/20 [1:36:37<1:57:59, 643.59s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 9, Loss: 0.5521328441264325\n"]},{"name":"stderr","output_type":"stream","text":[" 50%|█████     | 10/20 [1:47:22<1:47:18, 643.88s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 10, Loss: 0.435980809289914\n"]},{"name":"stderr","output_type":"stream","text":[" 55%|█████▌    | 11/20 [1:57:59<1:36:16, 641.78s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 11, Loss: 0.3940107787225387\n"]},{"name":"stderr","output_type":"stream","text":[" 60%|██████    | 12/20 [2:08:44<1:25:44, 643.01s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 12, Loss: 0.33753938586318666\n"]},{"name":"stderr","output_type":"stream","text":[" 65%|██████▌   | 13/20 [2:19:25<1:14:55, 642.16s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 13, Loss: 0.44071187921592947\n"]},{"name":"stderr","output_type":"stream","text":[" 70%|███████   | 14/20 [2:30:23<1:04:42, 647.03s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 14, Loss: 0.45039355516642177\n"]},{"name":"stderr","output_type":"stream","text":[" 75%|███████▌  | 15/20 [2:41:28<54:22, 652.40s/it]  "]},{"name":"stdout","output_type":"stream","text":["Epoch 15, Loss: 0.4167664403854125\n"]},{"name":"stderr","output_type":"stream","text":[" 80%|████████  | 16/20 [2:52:38<43:50, 657.70s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 16, Loss: 0.45542165295779097\n"]},{"name":"stderr","output_type":"stream","text":[" 85%|████████▌ | 17/20 [3:03:27<32:45, 655.02s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 17, Loss: 0.5170174255251163\n"]},{"name":"stderr","output_type":"stream","text":[" 90%|█████████ | 18/20 [3:14:16<21:46, 653.37s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 18, Loss: 0.41903505173759736\n"]},{"name":"stderr","output_type":"stream","text":[" 95%|█████████▌| 19/20 [3:24:59<10:50, 650.28s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 19, Loss: 0.4142303459766695\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 20/20 [3:35:43<00:00, 647.18s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 20, Loss: 0.38358494355073625\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["# Fine-tune the model\n","for epoch in tqdm(range(20)):\n","    model.train()\n","    train_loss = 0\n","    for i, row in df_tot.iterrows():\n","        input_ids, attention_mask, labels = format_inputs(row['text'], row['hard_label'])\n","        input_ids = input_ids.to(device)\n","        attention_mask = attention_mask.to(device)\n","        labels = labels.to(device)\n","\n","        optimizer.zero_grad()\n","        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n","        loss = outputs[0]\n","        train_loss += loss.item()\n","        loss.backward()\n","        optimizer.step()\n","    print(f'Epoch {epoch+1}, Loss: {train_loss/len(df_tot)}')"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Save/load the fine-tuned model"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[],"source":["torch.save(model, './model/fine_tuned_bert.pth')"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"data":{"text/plain":["('./tokenizer/tokenizer_config.json',\n"," './tokenizer/special_tokens_map.json',\n"," './tokenizer/vocab.txt',\n"," './tokenizer/added_tokens.json')"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer.save_pretrained('./tokenizer/')"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["model=torch.load('./model/fine_tuned_bert.pth')"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["# if the model is on cpu\n","model = model.to(device)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Test the model on Dev data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qtX8HHe8xDhQ"},"outputs":[],"source":["# Test the model\n","model.eval()\n","test_loss = 0\n","for i, row in df_tot.iterrows():\n","    input_ids, attention_mask, labels = format_inputs(row['text'], row['hard_label'])\n","    input_ids = input_ids.to(device)\n","    attention_mask = attention_mask.to(device)\n","    labels = labels.to(device)\n","\n","    outputs = model(input_ids, attention_mask=attention_mask)\n","    logits = outputs[0]\n","    test_loss += loss"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"xMqo1FgJxT1u"},"outputs":[],"source":["# Helper function for getting predictions\n","def get_predictions(model, dataframe):\n","    predictions = []\n","    model.eval()\n","    for i, row in dataframe.iterrows():\n","        input_ids, attention_mask, _ = format_inputs(row['text'], row['hard_label'])\n","        input_ids = input_ids.to(device)\n","        attention_mask = attention_mask.to(device)\n","        \n","        outputs = model(input_ids, attention_mask=attention_mask)\n","        logits = outputs[0]\n","        pred = logits.argmax(dim=1).item()\n","        predictions.append(pred)\n","    return predictions"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"UNKNOaF6xV49"},"outputs":[],"source":["# Get predictions for the test set\n","test_predictions = get_predictions(model, df_dev)"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":167,"status":"ok","timestamp":1674463601351,"user":{"displayName":"Giulia Rizzi","userId":"13349830956359138572"},"user_tz":-60},"id":"DEzHuouoxXuF","outputId":"cbb410cd-731e-4e55-c977-618627364a43"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.7408829174664108\n"]}],"source":["# Compare predictions to true labels\n","df_dev['predictions'] = test_predictions\n","correct_predictions = df_dev[df_dev['hard_label'] == df_dev['predictions']]\n","accuracy = len(correct_predictions) / len(df_dev)\n","print(f'Accuracy: {accuracy}')"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"IOyFgPefyJpJ"},"source":["### Integrated Gradient\n","\n","This code will use the integrated gradients method to calculate the attribution of each token in the input text to the final prediction of the model. The result is a list of values for each token, showing how much each token contributes to the final prediction.\n","You can also use other attribution methods such as ShapleyValue, Saliency or Deconvolution that are also available in captum library."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Integrated Gradient cod re-adapted from the Solutions proposed by vfdev-5 in https://github.com/pytorch/captum/issues/150\n","\n","More details about captrum visualization at https://github.com/pytorch/captum/blob/master/captum/attr/_utils/visualization.py"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Implementation details:\n","Number of Integrated Gradient steps = 200"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"tT0kstNh4Da-"},"outputs":[],"source":["from captum.attr import IntegratedGradients\n","import torch\n","import torch.nn as nn\n","\n","from transformers import BertTokenizer\n","from transformers import BertForSequenceClassification, BertConfig\n","\n","from captum.attr import IntegratedGradients\n","from captum.attr import InterpretableEmbeddingBase, TokenReferenceBase\n","from captum.attr import visualization\n","from captum.attr import configure_interpretable_embedding_layer, remove_interpretable_embedding_layer\n","\n","\n","# We need to split forward pass into two part: \n","# 1) embeddings computation\n","# 2) classification\n","\n","def compute_bert_outputs(model_bert, embedding_output, attention_mask=None, head_mask=None):\n","    if attention_mask is None:\n","        attention_mask = torch.ones(embedding_output.shape[0], embedding_output.shape[1]).to(embedding_output)\n","\n","    extended_attention_mask = attention_mask.unsqueeze(1).unsqueeze(2)\n","\n","    extended_attention_mask = extended_attention_mask.to(dtype=next(model_bert.parameters()).dtype) # fp16 compatibility\n","    extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n","\n","    if head_mask is not None:\n","        if head_mask.dim() == 1:\n","            head_mask = head_mask.unsqueeze(0).unsqueeze(0).unsqueeze(-1).unsqueeze(-1)\n","            head_mask = head_mask.expand(model_bert.config.num_hidden_layers, -1, -1, -1, -1)\n","        elif head_mask.dim() == 2:\n","            head_mask = head_mask.unsqueeze(1).unsqueeze(-1).unsqueeze(-1)  # We can specify head_mask for each layer\n","        head_mask = head_mask.to(dtype=next(model_bert.parameters()).dtype) # switch to fload if need + fp16 compatibility\n","    else:\n","        head_mask = [None] * model_bert.config.num_hidden_layers\n","\n","    encoder_outputs = model_bert.encoder(embedding_output,\n","                                         extended_attention_mask,\n","                                         head_mask=head_mask)\n","    sequence_output = encoder_outputs[0]\n","    pooled_output = model_bert.pooler(sequence_output)\n","    outputs = (sequence_output, pooled_output,) + encoder_outputs[1:]  # add hidden_states and attentions if they are here\n","    return outputs  # sequence_output, pooled_output, (hidden_states), (attentions)    "]},{"cell_type":"code","execution_count":13,"metadata":{"id":"P3WBEMwn4GGP"},"outputs":[],"source":["class BertModelWrapper(nn.Module):\n","    \n","    def __init__(self, model):\n","        super(BertModelWrapper, self).__init__()\n","        self.model = model\n","        \n","    def forward(self, embeddings):        \n","        outputs = compute_bert_outputs(self.model.bert, embeddings)\n","        pooled_output = outputs[1]\n","        pooled_output = self.model.dropout(pooled_output)\n","        logits = self.model.classifier(pooled_output)\n","        return torch.softmax(logits, dim=1)[:, 1].unsqueeze(1)"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"h60sdmfP4Nmh"},"outputs":[],"source":["bert_model_wrapper = BertModelWrapper(model)\n","ig = IntegratedGradients(bert_model_wrapper)"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"5VWutZyH4SMc"},"outputs":[],"source":["# accumalate couple samples in this array for visualization purposes\n","vis_data_records_ig = []"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"cgNTv3Yx3KBj"},"outputs":[],"source":["def interpret_sentence(model_wrapper, sentence, label=1):\n","\n","    model_wrapper.eval()\n","    model_wrapper.zero_grad()\n","    \n","    input_ids = torch.tensor([tokenizer.encode(sentence, add_special_tokens=True)]).to(device)\n","    \n","    input_embedding = model_wrapper.model.bert.embeddings(input_ids)\n","    \n","    # predict\n","    pred = model_wrapper(input_embedding).item()\n","    pred_ind = round(pred)\n","\n","    # compute attributions and approximation delta using integrated gradients\n","    attributions_ig, delta = ig.attribute(input_embedding, n_steps=200, return_convergence_delta=True)\n","\n","    print('pred: ', pred_ind, '(', '%.2f' % pred, ')', ', delta: ', abs(delta))\n","    tokens = tokenizer.convert_ids_to_tokens(input_ids[0].cpu().data.numpy().tolist())    \n","    \n","    #add_attributions_to_visualizer(attributions_ig, tokens, pred, pred_ind, label, delta, vis_data_records_ig)\n","    return attributions_ig, tokens, pred, pred_ind, label, delta, vis_data_records_ig\n","    \n","    \n","def add_attributions_to_visualizer(attributions, tokens, pred, pred_ind, label, delta, vis_data_records):\n","    #Additional method to visualize the results achieved through interpret_sentence\n","    attributions = attributions.sum(dim=2).squeeze(0)\n","    attributions = attributions / torch.norm(attributions)\n","    attributions = attributions.detach().cpu().data.numpy()\n","    \n","    # storing couple samples in an array for visualization purposes\n","    vis_data_records.append(visualization.VisualizationDataRecord(\n","                            attributions,\n","                            pred,\n","                            pred_ind,\n","                            label,\n","                            \"hard_label\",\n","                            attributions.sum(),       \n","                            tokens[:len(attributions)],\n","                            delta))    \n"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>hard_label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Cheap £ means foreigners will be flocking here...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>#BrexitOrNot ?? Easy!! #BREXIT and protect you...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>&lt;user&gt; #brexit to sum it up in just one word \"...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Putin says #Brexit reflects unhappiness with m...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>#Brexit is looking likely. but anti-immigratio...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2079</th>\n","      <td>Can’t let the scumbags on Wall Street try any ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2080</th>\n","      <td>&lt;user&gt; you are full of BS. #munchinLies</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2081</th>\n","      <td>Oral sex, too. Pat, how come you didn't have a...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2082</th>\n","      <td>&lt;user&gt; He’s the only President in history to d...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2083</th>\n","      <td>&lt;user&gt; &lt;user&gt; &lt;user&gt; &lt;user&gt; &lt;user&gt; &lt;user&gt; Cnn ...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2084 rows × 2 columns</p>\n","</div>"],"text/plain":["                                                   text  hard_label\n","0     Cheap £ means foreigners will be flocking here...           0\n","1     #BrexitOrNot ?? Easy!! #BREXIT and protect you...           0\n","2     <user> #brexit to sum it up in just one word \"...           0\n","3     Putin says #Brexit reflects unhappiness with m...           0\n","4     #Brexit is looking likely. but anti-immigratio...           0\n","...                                                 ...         ...\n","2079  Can’t let the scumbags on Wall Street try any ...           0\n","2080            <user> you are full of BS. #munchinLies           1\n","2081  Oral sex, too. Pat, how come you didn't have a...           1\n","2082  <user> He’s the only President in history to d...           0\n","2083  <user> <user> <user> <user> <user> <user> Cnn ...           1\n","\n","[2084 rows x 2 columns]"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["df_dev = df_dev.reset_index()\n","df_dev=df_dev[['text','hard_label']]\n","df_dev"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>text</th>\n","      <th>hard_label</th>\n","      <th>predictions</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>Cheap £ means foreigners will be flocking here...</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>#BrexitOrNot ?? Easy!! #BREXIT and protect you...</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>&lt;user&gt; #brexit to sum it up in just one word \"...</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>Putin says #Brexit reflects unhappiness with m...</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>#Brexit is looking likely. but anti-immigratio...</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2079</th>\n","      <td>1100</td>\n","      <td>Can’t let the scumbags on Wall Street try any ...</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2080</th>\n","      <td>1101</td>\n","      <td>&lt;user&gt; you are full of BS. #munchinLies</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2081</th>\n","      <td>1102</td>\n","      <td>Oral sex, too. Pat, how come you didn't have a...</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2082</th>\n","      <td>1103</td>\n","      <td>&lt;user&gt; He’s the only President in history to d...</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2083</th>\n","      <td>1104</td>\n","      <td>&lt;user&gt; &lt;user&gt; &lt;user&gt; &lt;user&gt; &lt;user&gt; &lt;user&gt; Cnn ...</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2084 rows × 4 columns</p>\n","</div>"],"text/plain":["      index                                               text  hard_label  \\\n","0         1  Cheap £ means foreigners will be flocking here...           0   \n","1         2  #BrexitOrNot ?? Easy!! #BREXIT and protect you...           0   \n","2         3  <user> #brexit to sum it up in just one word \"...           0   \n","3         4  Putin says #Brexit reflects unhappiness with m...           0   \n","4         5  #Brexit is looking likely. but anti-immigratio...           0   \n","...     ...                                                ...         ...   \n","2079   1100  Can’t let the scumbags on Wall Street try any ...           0   \n","2080   1101            <user> you are full of BS. #munchinLies           1   \n","2081   1102  Oral sex, too. Pat, how come you didn't have a...           1   \n","2082   1103  <user> He’s the only President in history to d...           0   \n","2083   1104  <user> <user> <user> <user> <user> <user> Cnn ...           1   \n","\n","      predictions  \n","0               0  \n","1               0  \n","2               0  \n","3               0  \n","4               0  \n","...           ...  \n","2079            0  \n","2080            0  \n","2081            0  \n","2082            0  \n","2083            0  \n","\n","[2084 rows x 4 columns]"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["df_dev = df_dev.reset_index()\n","df_dev"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fmzv7qdWTpqk"},"outputs":[],"source":["df_dev['attention']=0\n","df_dev['tokens']=''\n","for index, row in tqdm(df_dev.iterrows()):\n","  attributions_ig, tokens, _, _, _, _, _ = interpret_sentence(bert_model_wrapper, sentence=df_dev.loc[index, 'text'], label=0)\n","  attributions = attributions_ig.sum(dim=2).squeeze(0)\n","  attributions = attributions / torch.norm(attributions)\n","  attributions = attributions.detach().cpu().data.numpy()\n","  df_dev.loc[index, 'attention'] = str(attributions)\n","  df_dev.loc[index, 'tokens'] = str(tokens)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_dev.to_csv('./Data/IG_complete_100.csv', sep='\\t', index=False)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Alternative compact code version for saving computional space"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["def interpret_sentence(model_wrapper, sentence, label=1):\n","\n","    model_wrapper.eval()\n","    model_wrapper.zero_grad()\n","    \n","    input_ids = torch.tensor([tokenizer.encode(sentence, add_special_tokens=True)]).to(device)\n","    \n","    input_embedding = model_wrapper.model.bert.embeddings(input_ids)\n","    \n","    # compute attributions and approximation delta using integrated gradients\n","    attributions_ig, _ = ig.attribute(input_embedding, n_steps=200, return_convergence_delta=True)\n","    del model_wrapper\n","    gc.collect()\n","    torch.cuda.empty_cache()\n","\n","    tokens = tokenizer.convert_ids_to_tokens(input_ids[0].cpu().data.numpy().tolist())    \n","\n","    return attributions_ig, tokens"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_dev['attention']=0\n","df_dev['tokens']=''\n","for index, row in tqdm(df_dev.iterrows()):\n","  attributions_ig, tokens = interpret_sentence(bert_model_wrapper, sentence=df_dev.loc[index, 'text'], label=0)\n","  attributions_ig = attributions_ig.sum(dim=2).squeeze(0)\n","  attributions_ig = attributions_ig / torch.norm(attributions_ig)\n","  attributions_ig = attributions_ig.detach().cpu().data.numpy()\n","  df_dev.loc[index, 'attention'] = str(attributions_ig)\n","  df_dev.loc[index, 'tokens'] = str(tokens)\n","\n","  \n","  del attributions_ig, tokens\n","  gc.collect()\n","  torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_dev.to_csv('./Data/IG_complete_100.csv', sep='\\t', index=False)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Semeval23","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.16 (default, Jan 17 2023, 22:25:28) [MSC v.1916 64 bit (AMD64)]"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"fa8861d37e63998a7b0ab8e344e18a68a9508aa82c22311e5e069af7f7720f68"}}},"nbformat":4,"nbformat_minor":0}
